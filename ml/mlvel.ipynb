{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlvel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DvSyutLhPtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing ...\n",
        "import os\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import urllib.parse\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPZuI2iliieq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadFile(name):\n",
        "  directory = str(os.getcwd())\n",
        "  filepath = os.path.join(directory , name)\n",
        "  with open(filepath , 'r') as f :\n",
        "    data = f.readlines()\n",
        "  data = list(set(data))\n",
        "  result = []\n",
        "  for d in data :\n",
        "      d = str(urllib.parse.unquote(d))\n",
        "      result.append(d)\n",
        "  return result\n",
        "badQueries = loadFile('badqueries.txt')\n",
        "validQueries = loadFile('goodqueries.txt')\n",
        "\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPLRAAgiq1g8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "badQueries = list(set(badQueries))\n",
        "validQueries = list(set(validQueries))\n",
        "allQueries = badQueries + validQueries\n",
        "yBad = [1 for i in range(0, len(badQueries))]\n",
        "yGood = [0 for i in range(0, len(validQueries))]\n",
        "y = yBad + yGood\n",
        "queries = allQueries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iawCTq2brZY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\" , sublinear_tf=True, ngram_range=(1,3)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDlInE9-tX2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = vectorizer.fit_transform(queries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nPXkxpBt4K1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(x , y , test_size=0.2 , random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1CJV49zyQKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "badCount = len(badQueries)\n",
        "validCount = len(validQueries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcr3yL2L8tBM",
        "colab_type": "code",
        "outputId": "8b3b2eaf-8503-4099-8787-fb060c7bcbbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "lgs = LogisticRegression(class_weight={1: 2 * validCount / badCount, 0: 1.0})\n",
        "lgs.fit(X_train, y_train)\n",
        "predicted = lgs.predict(X_test)\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, (lgs.predict_proba(X_test)[:, 1]))\n",
        "auc = metrics.auc(fpr, tpr)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozZBxMBD8_LY",
        "colab_type": "code",
        "outputId": "0ee5fff6-55e3-44ad-9984-4d8ec1c36dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(\"Welcome To FSociety !@____@!\")\n",
        "print(\"Bad samples: %d\" % badCount)\n",
        "print(\"Good samples: %d\" % validCount)\n",
        "print(\"Baseline Constant negative: %.6f\" % (validCount / (validCount + badCount)))\n",
        "print(\"-*-*-*-*-*-*-*-*-*-*-*-\")\n",
        "print(\"Accuracy: %f\" % lgs.score(X_test, y_test))\n",
        "print(\"Precision: %f\" % metrics.precision_score(y_test, predicted))\n",
        "print(\"Recall: %f\" % metrics.recall_score(y_test, predicted))\n",
        "print(\"F1-Score: %f\" % metrics.f1_score(y_test, predicted))\n",
        "print(\"AUC: %f\" % auc)\n",
        "print(\"\\nBy Team FSociety \\n\\n\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome To FSociety !@____@!\n",
            "Bad samples: 44532\n",
            "Good samples: 1265974\n",
            "Baseline Constant negative: 0.966019\n",
            "-*-*-*-*-*-*-*-*-*-*-*-\n",
            "Accuracy: 0.999405\n",
            "Precision: 0.984287\n",
            "Recall: 0.998179\n",
            "F1-Score: 0.991184\n",
            "AUC: 0.999979\n",
            "\n",
            "By Team FSociety \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}